<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Self Localization</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-opaquegray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="b853aa24-4063-42a2-bc03-8138108fffe8" class="page sans"><header><img class="page-cover-image" src="Self%20Localization%20b853aa24406342a2bc038138108fffe8/Screen_Shot_2022-09-13_at_2.21.19_PM.png" style="object-position:center 50%"/><h1 class="page-title">Self Localization</h1></header><div class="page-body"><p id="bdcae419-3814-46f0-b667-dfc3ada7c4b4" class="block-color-gray"><a href="Self%20Localization%20b853aa24406342a2bc038138108fffe8.html">1 · Introduction</a> </p><p id="97aeb80c-fd5b-480f-aca9-a700d99f908b" class=""><a href="Self%20Localization%20b853aa24406342a2bc038138108fffe8.html">2 · Dataset Download</a> </p><p id="550f6452-1b87-4c2d-88db-03fe3ec648b6" class="block-color-gray"><a href="Self%20Localization%20b853aa24406342a2bc038138108fffe8.html">3 · Dataset Structure</a> </p><p id="268c4c9f-6a7e-4ad9-b457-57d3f7fed927" class=""><a href="Self%20Localization%20b853aa24406342a2bc038138108fffe8.html">4 · Evaluation</a> </p><p id="7cb3289d-634e-48ee-b678-5c73b9a23960" class=""><a href="Self%20Localization%20b853aa24406342a2bc038138108fffe8.html">5 · Metric formula</a> </p><p id="40428fdb-3547-406e-991f-2b7c43cf6d89" class=""><a href="Self%20Localization%20b853aa24406342a2bc038138108fffe8.html">6 · Rules of ranking</a> </p><p id="48ce0cfe-606f-4ae0-a18a-d04fc96bd7f1" class=""><a href="Self%20Localization%20b853aa24406342a2bc038138108fffe8.html">7 · Submission of data format</a> </p><p id="a1b20cac-8496-4af7-8aa4-a45bd6879ff5" class="">
</p><p id="29412032-28ea-413d-bfb1-62a2f0cd9e43" class="">This repository contains the evaluation scripts for the online self-localization challenge of the ApolloScapes dataset, Where we extended the dataset with more scenes and 100x large data including recorded videos under different lighting conditions, i.e. morning, noon and night. A test dataset for each new scene will be withheld for benchmark. (Notice we will not have point cloud for the very large data due to size of dataset)</p><h1 id="1e884e4e-d47e-40f6-af4f-e5ecbd19bd89" class="">1 · Introduction</h1><p id="48835605-67a1-4d9b-a478-0adef09f30f1" class="">This repository contains the evaluation scripts for the online self-localization challenge of the ApolloScapes dataset, Where we extended the dataset with more scenes and 100x large data including recorded videos under different lighting conditions, i.e. morning, noon and night, with stereo pair of images. A test dataset for each new scene will be withheld for benchmark. (Notice we will not have point cloud for the very large data due to size of dataset).</p><p id="8ec19e6a-972d-467d-9901-1a4bfa5b1286" class="">Details and download of data from different roads are available. Here are some interesting facts:</p><p id="2d01cf9a-44db-4266-8372-d1033a281871" class=""><em>For each road, we record it by driving from start-to-end and then end-to-start at different day times, which means at each site along the road, a scene will be looked at from two opposite directions. We provide the set of record id recorded from start-to-end and the set of record id from end-to-start in training set for each road at LoopDirection. One may discover the corresponding images from the camera pose we provided.</em></p><p id="b51d272f-7e70-479c-870e-c445c0782558" class=""><em>In this challenge, we record records from forward (start-to-end) and inverse (end-to-start) driving as records from two different roads, which means we will not have forward videos as training while have inverse driving as testing videos. However, it could be interesting to do that in your research as showed in the work of Semantic Visual Localization.</em></p><figure id="cc8f1e0b-4d8e-4ec1-a56f-ba99d8358a29" class="image"><a href="Self%20Localization%20b853aa24406342a2bc038138108fffe8/datasets-self-localization_b445704.gif"><img style="width:413px" src="Self%20Localization%20b853aa24406342a2bc038138108fffe8/datasets-self-localization_b445704.gif"/></a></figure><h1 id="7e28938e-8f0f-4549-b42d-3df4adb80ea5" class="">2 · Dataset Download</h1><p id="39aad85d-292b-4f93-a95f-8f854c6556ce" class=""><strong>Sample data</strong></p><p id="b3cacaa6-d9e0-4f18-ba94-034f27253936" class=""><a href="https://ad-apolloscape.cdn.bcebos.com/self-localization-sample.tar.gz">self-localization-sample</a></p><p id="8bb457bd-acfc-4701-8746-ced6d4cb3cea" class="">
</p><p id="e12ecd8f-d54f-48a2-92e6-2fd2dcd52820" class=""><strong>Full Data</strong></p><p id="2e10a08b-e3db-435c-bc37-a60ccf80d70a" class="">For full Training data and Testing data, Please email apolloscape at <a href="http://baidu.com">baidu.com</a> to download</p><h1 id="bae9502b-ad01-4d0e-9c1f-89971ce659c9" class="">3 · Dataset Structure</h1><p id="dc0633ae-55ed-4153-beec-79dae3e3a488" class="">You may download the dataset from <a href="http://apolloscape.auto/ECCV/challenge.html">self-localization</a>. The sample data is used for paper</p><pre id="552f795e-e115-4b47-b6b4-400b2c08fe9f" class="code code-wrap"><code> @inproceedings{wang2018dels,
                   title={DeLS-3D: Deep Localization and Segmentation with a 3D Semantic Map},
                   author={Wang, Peng and Yang, Ruigang and Cao, Binbin and Xu, Wei and Lin, Yuanqing},
                   booktitle={CVPR},
                   pages={5860--5869},
                   year={2018}
                 }
</code></pre><p id="f700fbf3-2aef-497b-a462-86fb8328a72a" class=""><code>scene_names</code> include a sample scene:</p><ul id="ff0e27f6-b0c8-4150-9aa6-c7f04b22c4c6" class="bulleted-list"><li style="list-style-type:disc"><code>Road_01</code>: which is a small dataset with 2242 train/756 val images recorded in the same scene</li></ul><p id="128e02d0-fa0f-4383-b75c-264fbb9bd3b9" class=""><code>data_type</code> includes:</p><ul id="3a92b5e1-9a9c-4caa-bda1-feac91f0f530" class="bulleted-list"><li style="list-style-type:disc"><code>image</code>: the RGB image from the dataset</li></ul><ul id="b1783323-c059-4535-97c9-75755eb5be28" class="bulleted-list"><li style="list-style-type:disc"><code>pose</code>: the abosolute pose (roll,pitch,yall,x,y,z) of each image related to a map (Notice this is converted from the 4x4 pose matrix from Apolloscape dataset)</li></ul><ul id="57428ec0-80ac-4af2-8929-a0ea8fdab489" class="bulleted-list"><li style="list-style-type:disc"><code>camera_params</code>: the intrinsic parameter of the camera</li></ul><ul id="665bf97e-ae99-4bbd-8567-bb5f93163215" class="bulleted-list"><li style="list-style-type:disc"><code>split</code>: the train val split used in the paper</li></ul><p id="2010049f-26ee-41ec-a17a-2a5b73ae10e2" class=""><code>sequence_id</code>, each sequence, i.e. Recordxxx is a video sequence of the corresponding scene and the images are sorted numerically.</p><p id="b9d07bbd-5818-4baf-93ea-fd386e6a4e24" class=""><code>camera_id</code>, each scene we provide images recorede by two camera facing front side.</p><ul id="1d6806b6-74f8-4f04-804d-a5d062de78cb" class="bulleted-list"><li style="list-style-type:disc"><code>zpark</code>: <code>Camera_1</code> and <code>Camera_2</code> There is a camera-name in-consistency of the device between the two scene, which will be fixed for the larger dataset later.</li></ul><p id="cd8ff489-807b-489c-9166-11d9bd9103fb" class="">Here <code>split</code> include the train and val image names for each scene, where val images are recorded at different period with training images.</p><p id="6f87c0a0-12ba-4a29-b009-322bfdad4998" class="">Similar data structure is described in apolloscape.auto/scene.html, while having the pose saved in a 4x4 matrix, a conversion code from 4x4 matrix to 6 DOF is provided in <code>utils</code> of this toolkit.</p><p id="3a27ce22-c2f5-450b-a501-914b7f664e95" class="">Later we will also release semantic labels, and semantic 3d point cloud python toolkit to render 3d point to 2d image for visualizing the semantic points.</p><h1 id="1496d3da-b63d-4c81-80b6-443f79076b1a" class="">4 · Evaluation</h1><p id="6850e59d-c5e9-4cee-9623-cf4d7d437d1b" class="">There are several scripts included with the dataset in a folder named <code>scripts</code></p><ul id="d0b6d892-3d2d-4826-93ee-61c24db80de8" class="bulleted-list"><li style="list-style-type:disc"><code>eval_pose.py</code> Code for evalution pose accuracy based the commonly used eval metric of meidian translation and rotation error.</li></ul><p id="335b110e-78f3-4109-adbe-4566685dad74" class="">Code for test evaluation:</p><pre id="53874fef-1199-4170-9b62-f4bc836b446c" class="code code-wrap"><code>#!/bin/bash
                            python eval_pose.py --test_dir=&#x27;./test_eval_data/pose_res&#x27; --gt_dir=&#x27;./test_eval_data/pose_gt&#x27; --res_file=&#x27;./test_eval_data/res.txt&#x27;</code></pre><h1 id="38e5106b-bf13-4deb-8750-8185fe8af32a" class="">5 · Metric formula</h1><p id="eb47a821-7fa0-4825-882c-2396a45e03f9" class="">For each image, given the predicted rotation  and translation  of image , and the ground truth  and , the metric for evaluation is defined as:</p><p id="be07725e-378d-4308-849a-3ab23d3d2a93" class="">where  is the quaternions representation of the Euler angle <code>row, pitch, yall</code></p><h1 id="9090b3ad-1a08-4b18-93a4-00a6ee2a93ae" class="">6 · Rules of ranking</h1><p id="08fb9f0c-4592-4680-82fb-831b241df245" class="">Result benchmark will be:</p><p id="c8ead7dd-9504-48cc-a898-c3bf3f5635f0" class="">Our ranking will determined by number of winning metrics from all scenes.</p><h1 id="426f6b20-ce33-4634-accb-538832a197be" class="">7 · Submission of data format</h1><p id="a770f852-47b8-4487-a76b-64daf379087c" class="">Please follow the data format under <code>test_eval_data/</code> for example.</p><ul id="dbb03ff1-71f1-41be-9c17-53776e55ed74" class="bulleted-list"><li style="list-style-type:disc">Example dir tree of submitted zip file</li></ul><pre id="11ce4cc7-07e8-4b31-a1bf-77d38de24645" class="code code-wrap"><code>├── test
                │   ├── scene1
                │   │   ├── sequence1.txt
                │   │   ├── sequence2.txt
                │   │    ...
                │   ├── scene2
                │   │   ├── sequence1.txt
                │   │   ├── sequence2.txt
                ...</code></pre><ul id="ad473911-52de-48a3-b703-d9987ef75520" class="bulleted-list"><li style="list-style-type:disc">Example format of <code>sequence1.txt</code></li></ul><pre id="8d4e65cf-63cd-407e-bf48-483decfb8c72" class="code code-wrap"><code>image_name1 roll,pitch,yaw,x,y,z
                image_name2 roll,pitch,yaw,x,y,z
                image_name3 roll,pitch,yaw,x,y,z
                image_name4 roll,pitch,yaw,x,y,z
                image_name5 roll,pitch,yaw,x,y,z</code></pre><p id="c8087197-bb04-4711-84d9-d4b9455f1090" class="">Here <code>roll,pitch,yaw,x,y,z</code> are <code>float32</code> numbers</p><p id="9d128e55-8b23-400d-919d-5abbac4b4abb" class="">
</p><p id="6094125b-e02d-4354-80b6-39d88bad713b" class="">The dataset we released is desensitized street view for academic use only.</p></div></article></body></html>