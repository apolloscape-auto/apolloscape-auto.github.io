<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>ApolloScape Dataset</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-opaquegray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="2c8b5f64-8f53-4bfa-8e37-dfc195f8a8d6" class="page sans"><header><img class="page-cover-image" src="ApolloScape%20Dataset%202c8b5f648f534bfa8e37dfc195f8a8d6/Screen_Shot_2022-07-01_at_3.10.02_PM.png" style="object-position:center 50%"/><div class="page-header-icon page-header-icon-with-cover"><img class="icon" src="ApolloScape%20Dataset%202c8b5f648f534bfa8e37dfc195f8a8d6/40558316.png"/></div><h1 class="page-title">ApolloScape Dataset</h1></header><div class="page-body"><div id="11da1143-7a3a-4b67-bf4b-6d255f2a9ace" class="column-list"><div id="4eef6c1e-18bd-4484-85a2-c6483c4af298" style="width:25%" class="column"><figure id="88e9a03b-ff96-4aa7-a2f5-ff16d30700eb" class="link-to-page"><a href="https://www.notion.so/Trajectory-88e9a03bff964aa7a2f5ff16d30700eb">Trajectory</a></figure></div><div id="1111384d-f9c3-4491-bbfd-fbd1008f1e72" style="width:28.125%" class="column"><figure id="41cdd1cc-0b31-4da7-b2de-e97c1d6ce284" class="link-to-page"><a href="https://www.notion.so/3D-Lidar-Object-Detection-and-Tracking-41cdd1cc0b314da7b2dee97c1d6ce284">3D Lidar Object Detection and Tracking</a></figure></div><div id="0d8b2c99-a471-4e5d-a0f7-46d7df036249" style="width:21.875000000000004%" class="column"><figure id="d0e69548-0779-47b0-9be5-25c68a04db06" class="link-to-page"><a href="https://www.notion.so/Stereo-d0e69548077947b09be525c68a04db06">Stereo</a></figure></div><div id="1a7a150f-de22-45c5-9993-741060c5f27b" style="width:25%" class="column"><figure id="805c7718-29b6-43df-b16d-6538ab74dfe9" class="link-to-page"><a href="https://www.notion.so/Inpainting-805c771829b643dfb16d6538ab74dfe9">Inpainting</a></figure></div></div><div id="8fab3701-b343-4361-ba03-91498f79b1f4" class="column-list"><div id="96452eb3-b627-4090-9893-efe3442355d5" style="width:25%" class="column"><figure id="ef8e701a-f48f-4376-abef-1d4cb2ec7225" class="link-to-page"><a href="https://www.notion.so/Scene-Parsing-ef8e701af48f4376abef1d4cb2ec7225">Scene Parsing</a></figure></div><div id="09dafdfa-204c-4ebe-b9f3-e849b30f5115" style="width:25%" class="column"><figure id="f1daa65f-4c94-4996-9f17-1f73a6047705" class="link-to-page"><a href="https://www.notion.so/3D-Car-Instance-f1daa65f4c9449969f171f73a6047705">3D Car Instance</a></figure></div><div id="55023ad7-c677-4296-8a8e-c9d89004e0e4" style="width:25%" class="column"><figure id="c94d1ff2-c92c-4351-9f0d-5de0d8b8a21e" class="link-to-page"><a href="https://www.notion.so/Lane-Segmentation-c94d1ff2c92c43519f0d5de0d8b8a21e">Lane Segmentation</a></figure></div><div id="58f59713-6366-4eae-ba34-c7a66db489cc" style="width:25%" class="column"><figure id="b853aa24-4063-42a2-bc03-8138108fffe8" class="link-to-page"><a href="https://www.notion.so/Self-Localization-b853aa24406342a2bc038138108fffe8">Self Localization</a></figure></div></div><h2 id="6569cd10-1c8e-416a-881b-49857ad23f82" class=""><strong>About ApolloScape Dataset</strong></h2><div id="0a92bedc-fa95-4791-be4c-0586ab559084" class="column-list"><div id="1bda1290-5d67-4f4b-b26a-75ac349cd87b" style="width:68.75%" class="column"><p id="20c4b5f0-960c-4db8-8a68-b7f27c9e9fc5" class="">Trajectory dataset, 3D Perception Lidar Object Detection and Tracking dataset including about 100K image frames, 80k lidar point cloud and 1000km trajectories for urban traffic. The dataset consisting of varying conditions and traffic densities which includes many challenging scenarios where vehicles, bicycles, and pedestrians move among one another. Please checkout toolkit on Github <a href="https://github.com/ApolloScapeAuto/dataset-api">Toolkit for ApolloScape Dataset</a>.</p></div><div id="84c8f46b-29f7-4314-b8dd-01dded63f014" style="width:31.249999999999993%" class="column"><figure id="6967b69b-1bc9-4e31-9d3c-1095381e3f55" class="image"><a href="ApolloScape%20Dataset%202c8b5f648f534bfa8e37dfc195f8a8d6/intro-simulation_840bea5.jpg"><img style="width:288px" src="ApolloScape%20Dataset%202c8b5f648f534bfa8e37dfc195f8a8d6/intro-simulation_840bea5.jpg"/></a></figure></div></div><h2 id="ccc9e1f5-6699-485d-8748-4be54052af61" class=""><strong>Scene Parsing</strong></h2><div id="2b63de3f-d745-45fa-8a65-ce4dd9b83240" class="column-list"><div id="260c8ffe-6ac0-4764-88a4-ab1d98e78d55" style="width:68.75%" class="column"><p id="e302eebe-47f6-496d-a90f-2e7896fa0091" class="">The whole dataset will include RGB videos with high resolution image sequences and per pixel annotation, survey-grade dense 3D points with semantic segmentation. Our continuous collection will further add more sensors, such as stereoscopic video and panoramic images; and cover a wide range of environment, weather, and traffic conditions. Scene Parsing dataset provides 146,997 frames with corresponding pixel-level annotations and pose information, depth maps for static background.</p><p id="bfc9d7c1-8167-4d3c-90ce-3cf2ffa4820f" class="">
</p></div><div id="90909dc1-9e95-477c-acb4-8e9edbb5b301" style="width:31.249999999999993%" class="column"><figure id="bd0c9ac5-95a8-4c37-b1c7-946115560a5a" class="image"><a href="ApolloScape%20Dataset%202c8b5f648f534bfa8e37dfc195f8a8d6/intro-scene_ca748b1.jpg"><img style="width:288px" src="ApolloScape%20Dataset%202c8b5f648f534bfa8e37dfc195f8a8d6/intro-scene_ca748b1.jpg"/></a></figure></div></div><h2 id="4fe31c53-ed1a-4817-b6d7-df961e4cea48" class=""><strong>Github Toolkit: </strong></h2><p id="9fdddcec-d74c-4ad0-879e-c3c2d8f22806" class=""><a href="https://github.com/ApolloScapeAuto/dataset-api">https://github.com/ApolloScapeAuto/dataset-api</a></p><p id="d7c5b70b-1893-49b8-b8f0-4f16eda9f760" class="">
</p><h2 id="c0b72555-0c8c-44c8-b739-c35528294a15" class=""><strong>Workshop:</strong></h2><p id="27607fe9-5ede-4ed7-9247-73acf65f7f14" class=""><a href="https://www.kaggle.com/c/pku-autonomous-driving">Kaggle Pku/Baidu Workshop on Autonomous Driving</a></p><div id="6775f9c8-0334-45b5-9c45-af5da4d4b655" class="column-list"><div id="2aef66c9-c5d6-4ef4-816c-db1bd5fd7b55" style="width:50%" class="column"><figure id="0ad14274-ba44-4335-9df8-702b93a94213" class="link-to-page"><a href="https://www.notion.so/CVPR-2019-Workshop-on-Autonomous-Driving-0ad14274ba4443359df8702b93a94213">CVPR 2019 - Workshop on Autonomous Driving</a></figure></div><div id="3a64fe34-8738-4422-a990-e433653fcaa9" style="width:50%" class="column"><figure id="c2a794a9-e9bf-4f03-8377-a2278a550da2" class="link-to-page"><a href="https://www.notion.so/ICCV-2019-Workshop-on-autonomous-driving-c2a794a9e9bf4f038377a2278a550da2">ICCV 2019 Workshop on autonomous driving</a></figure></div></div><div id="a2666233-20f0-45b9-969c-26521a2dc45d" class="column-list"><div id="c505006f-2312-4c47-a269-25428e5d6d4f" style="width:50%" class="column"><figure id="90714aa0-24c7-41fc-82df-136319de7e5a" class="link-to-page"><a href="https://www.notion.so/ECCV-2018-Vision-based-Navigation-for-Autonomous-Driving-90714aa024c741fc82df136319de7e5a">ECCV 2018: Vision-based Navigation for Autonomous Driving</a></figure></div><div id="e09bc106-9575-4cf5-b4f1-33f5b44e58a2" style="width:50%" class="column"><figure id="e3fc52ba-814a-40d4-b0f9-858b9c65ae57" class="link-to-page"><a href="https://www.notion.so/CVPR-2018-Workshop-on-Autonomous-Driving-e3fc52ba814a40d4b0f9858b9c65ae57">CVPR 2018 Workshop on Autonomous Driving</a></figure></div></div><p id="5a43fcac-f712-4958-834f-c1277877dce0" class="">
</p><h3 id="1e1366c8-c5b9-4a3b-b35e-cd4a8747b323" class="">Leaderboard:</h3><div id="28783202-4629-4e6a-8ca1-2131b6ba625b" class="column-list"><div id="48d22af4-ec3e-4e49-a0ed-86cd0fd91ffc" style="width:33.33333333333333%" class="column"><figure id="a3595fa5-89df-444d-88b4-2a08a2e97e07" class="link-to-page"><a href="https://www.notion.so/a3595fa589df444d88b42a08a2e97e07">Trajectory Leaderboard</a></figure><figure id="df422653-6dfd-404a-873c-f798892f765a" class="link-to-page"><a href="https://www.notion.so/df4226536dfd404a873cf798892f765a">Scene Parsing Leaderboard </a></figure><p id="db936126-b7df-4a97-9a44-ac7208e61cf3" class="">
</p></div><div id="e5349d89-c110-437c-b4b3-5bfdc75389be" style="width:33.33333333333333%" class="column"><figure id="6a0929e5-dc35-4462-a433-38e9b925a52a" class="link-to-page"><a href="https://www.notion.so/6a0929e5dc354462a43338e9b925a52a">Detection Leaderboard</a></figure><figure id="e497299c-ac62-407e-ba1d-18b17eede2a2" class="link-to-page"><a href="https://www.notion.so/e497299cac62407eba1d18b17eede2a2">Car Instance Leaderboard</a></figure></div><div id="2a43e5d5-8a00-4894-b489-9a6d30845c6a" style="width:33.33333333333333%" class="column"><figure id="c304cf0d-2541-4ad5-8111-d06a7e8b22e1" class="link-to-page"><a href="https://www.notion.so/c304cf0d25414ad58111d06a7e8b22e1">Tracking Leaderboard</a></figure><figure id="a0d47b0e-0df2-4436-beeb-f1f1281d0dd2" class="link-to-page"><a href="https://www.notion.so/a0d47b0e0df24436beebf1f1281d0dd2">Lane Segmentation Leaderboard</a></figure></div></div><h2 id="d836d8f8-84a6-477c-af5d-fa35175632ca" class=""><strong>News</strong></h2><h3 id="2e33cef1-b2cc-44ac-b06d-68d543686fe9" class=""><strong>Publication</strong></h3><ul id="75e87a88-2fef-4f22-adf1-d188a56b289e" class="bulleted-list"><li style="list-style-type:disc">DVI: Depth Guided Video Inpainting for Autonomous Driving. Miao Liao, Feixiang Lu, Dingfu Zhou, Sibo Zhang, Wei Li, and Ruigang Yang. European Conference on Computer Vision. ECCV 2020 <a href="https://arxiv.org/pdf/2007.08854.pdf">[PDF]</a> <a href="http://apolloscape.auto/inpainting.html">[Inpainting Dataset]</a> <a href="https://github.com/ApolloScapeAuto/dataset-api/tree/master/inpainting">[Github]</a> <a href="https://www.youtube.com/watch?v=iOIxdQIzjQs">[Result Video]</a> <a href="https://www.youtube.com/watch?v=_pcqH1illCU">[Presentation Video]</a> <a href="https://github.com/ApolloScapeAuto/dataset-api/blob/master/inpainting/dvi_bibtex.txt">[BibTex]</a></li></ul><ul id="39e437aa-6b2f-4c7c-8357-63bb66b7daa8" class="bulleted-list"><li style="list-style-type:disc">TrafficPredict: Trajectory Prediction for Heterogeneous Traffic-Agents. Yuexin Ma, Xinge Zhu, Sibo Zhang, Ruigang Yang, Wenping Wang, and Dinesh Manocha. The Thirty-Third AAAI Conference on Artificial Intelligence. AAAI 2019 (oral)<a href="https://arxiv.org/abs/1811.02146">[PDF]</a> <a href="http://apolloscape.auto/trajectory.html">[Trajectory Dataset]</a> <a href="https://github.com/ApolloScapeAuto/dataset-api/tree/master/trajectory_prediction">[Github]</a> <a href="http://gamma.cs.unc.edu/TPredict/TrafficPredict.html">[Webpage]</a> <a href="https://www.youtube.com/watch?v=dST6NDxEMU8">[Video]</a> <a href="https://ad-apolloscape.cdn.bcebos.com/TrafficPredict/trafficpredict_bibtex.txt">[BibTex]</a></li></ul><ul id="517f44f5-3010-4c1a-a46b-3990c50c7558" class="bulleted-list"><li style="list-style-type:disc">The apolloscape open dataset for autonomous driving and its application. Huang, Xinyu and Wang, Peng and Cheng, Xinjing and Zhou, Dingfu and Geng, Qichuan and Yang, Ruigang. IEEE transactions on pattern analysis and machine intelligence<a href="https://arxiv.org/pdf/1803.06184.pdf">[PDF]</a> <a href="http://apolloscape.auto/scene.html">[Scene Dataset]</a> <a href="https://ad-apolloscape.cdn.bcebos.com/public/apolloscape_bibTex.txt">[BibTex]</a></li></ul><ul id="a7465a49-8adc-4286-9c3f-4e8167abb99f" class="bulleted-list"><li style="list-style-type:disc">ApolloCar3D: A Large 3D Car Instance Understanding Benchmark for Autonomous Driving. Song, Xibin and Wang, Peng and Zhou, Dingfu and Zhu, Rui and Guan, Chenye and Dai, Yuchao and Su, Hao and Li, Hongdong and Yang, Ruigang. CVPR, 2019<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Song_ApolloCar3D_A_Large_3D_Car_Instance_Understanding_Benchmark_for_Autonomous_CVPR_2019_paper.pdf">[PDF]</a> <a href="http://apolloscape.auto/car_instance.html">[Car Instance Dataset]</a> <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:4bz3YPx9WkIJ:scholar.google.com/&amp;output=citation&amp;scisdr=CgXjlNWZEJrk-4FjBaA:AAGBfm0AAAAAXnBmHaCeBWXWonvsMbm0ij0q_vxC-vKO&amp;scisig=AAGBfm0AAAAAXnBmHc3l8OMlNK05P619INLviiYce4SD&amp;scisf=4&amp;ct=citation&amp;cd=-1&amp;hl=en">[BibTex]</a></li></ul><ul id="25abe9e9-9331-4a74-b2b4-9c9b4ed2b113" class="bulleted-list"><li style="list-style-type:disc">AADS: Augmented autonomous driving simulation using data-driven algorithms. Wei Li, Chengwei Pan, Rong Zhang, Jiaping Ren, Yuexin Ma, Jin Fang, Feilong Yan, Qichuan Geng, Xinyu Huang, Huajun Gong, Weiwei Xu, Guoping Wang, Dinesh Manocha, Ruigang Yang. Science Robotics, 2019<a href="https://arxiv.org/pdf/1901.07849.pdf">[PDF]</a></li></ul><h3 id="35748ee4-010e-4490-a2ae-1624ae9b7899" class=""><strong>Events Update</strong></h3><ul id="61e22487-5c34-4727-aee6-4b6170bf6c6e" class="bulleted-list"><li style="list-style-type:disc">2020.02 <a href="https://www.kaggle.com/c/pku-autonomous-driving">Kaggle Pku/Baidu Workshop on Autonomous Driving</a></li></ul><ul id="a57ed999-380d-4b35-9225-d6a35d04c554" class="bulleted-list"><li style="list-style-type:disc">2019.10 <a href="http://wad.ai/">ICCV 2019 Workshop on Autonomous Driving</a></li></ul><ul id="185732e2-6ba3-4968-8ce4-c74805ead310" class="bulleted-list"><li style="list-style-type:disc">2019.06 <a href="http://wad.ai/2019/">CVPR 2019 Workshop on Autonomous Driving</a> and CVPR 2019 <a href="http://wad.ai/2019/challenge.html">Trajectory and 3D Perception Challenge</a>. Summary <a href="https://arxiv.org/pdf/2004.05966.pdf">[PDF]</a></li></ul><ul id="ab5fadf4-ac82-46cf-a575-72d258b3839d" class="bulleted-list"><li style="list-style-type:disc">2018 <a href="http://wad.ai/2018/">CVPR 2018 Workshop on Autonomous Driving</a></li></ul><h3 id="2b1d2f7a-3b13-4c46-b931-9981026da312" class=""><strong>Dataset Update</strong></h3><ul id="8b4aad52-e60a-48e3-9c59-9479d6f7ac6c" class="bulleted-list"><li style="list-style-type:disc"><a href="https://github.com/ApolloScapeAuto/dataset-api">Toolkit for ApolloScape Dataset</a></li></ul><ul id="089c6302-8724-4def-99fc-050bdf838929" class="bulleted-list"><li style="list-style-type:disc">2020.09 Released <a href="http://apolloscape.auto/inpainting.html">Inpainting Dataset</a>, consists of synchronized Labeled image and LiDAR scanned point clouds.</li></ul><ul id="679903e5-2117-4312-b61a-7b82d0fd5323" class="bulleted-list"><li style="list-style-type:disc">2019.03 Released <a href="http://apolloscape.auto/tracking.html">3D Lidar Object Detection and Tracking Dataset</a>, contains 80k lidar point cloud for urban traffic</li></ul><ul id="319546bd-7a4c-4b53-9374-8cb85a60bda9" class="bulleted-list"><li style="list-style-type:disc">2019.02 Released <a href="http://apolloscape.auto/trajectory.html">Trajectory Dataset</a>, contains 1000km trajectories for urban traffic.</li></ul><ul id="c2f1b8b3-7c65-4ed8-8e89-5b57e75b92ad" class="bulleted-list"><li style="list-style-type:disc">2018.03.08 We have released the first part of the dataset that contains 74555 video frames and their pixel-level and instance-level annotations</li></ul><ul id="873fe78f-4020-44b9-a10e-5db78186a7ac" class="bulleted-list"><li style="list-style-type:disc">2018.03.21 We added the second part of the data set, including 43592 depth images for static background (road01_ins_depth&amp;road02_ins_depth)</li></ul><ul id="d8b73177-e433-4305-b375-952e7f136468" class="bulleted-list"><li style="list-style-type:disc">2018.03.29 Update the data set, including 30,963 depth images for static background (road03_ins_depth和road04_ins_depth)</li></ul><ul id="4fc0a76f-2fb1-4777-bb60-e302b384f960" class="bulleted-list"><li style="list-style-type:disc">2018.03.30 Update the data set, including 22,871 pixel-level images and depth images for static background (road02_seg和road02_seg_depth)</li></ul><ul id="5781f0cb-2a53-42ea-a5ac-b0c106313c30" class="bulleted-list"><li style="list-style-type:disc">2018.03.30 Uploaded the <a href="http://ad-apolloscape.bj.bcebos.com/public%2Fimage_lists.tar.gz">Image lists</a> for training, validation, and testing for road01_ins, road02_ins, and road03_ins</li></ul><ul id="a7c20e2b-6ea3-4749-9141-cfbb678b62b3" class="bulleted-list"><li style="list-style-type:disc">2018.04.03 Update the data set, including 49,571 pixel-level images and depth images for static background（road03_seg and road04_seg）</li></ul><ul id="4927703d-cef6-4958-b93e-d952f6079bfc" class="bulleted-list"><li style="list-style-type:disc">2018.04.03 Scene Parsing data set cumulatively provides 146,997 frames with corresponding pixel-level annotations and pose information，depth maps for static background.</li></ul><p id="e35608ae-4c82-4a02-a037-835574f66bb7" class="">
</p><p id="cc6a6efb-5536-429f-a07d-f3055d94a79d" class="">Please submit issue at <a href="https://github.com/ApolloScapeAuto/dataset-api">https://github.com/ApolloScapeAuto/dataset-api</a></p><p id="834aa7b4-fee6-4d6b-93e5-16a9b0cf4ee9" class="">
</p><figure id="6462c472-5521-4723-9d4b-7c4c043f0b91" class="link-to-page"><a href="https://www.notion.so/ApolloScape-User-License-6462c472552147239d4b7c4c043f0b91">ApolloScape User License</a></figure></div></article></body></html>