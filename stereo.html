<!DOCTYPE html><!--[if lt IE 9]><html class="ie"><![endif]--><html lang="en"><head><meta charset="UTF-8"><title>Apollo Scape</title><meta name="keywords" content="Apollo, Scape, Apollo Scape"><meta name="description" content="Baidu Apollo Scape"><meta name="viewport" content="width=device-width"><link rel="shortcut icon" href="/public/img/common/favicon.ico"><link rel="stylesheet" type="text/css" href="/css/common/base_23ab8c6.css"><link rel="stylesheet" type="text/css" href="/css/common/custom_5250103.css"><script type="text/javascript" src="/js/lib/jquery-3.2.1.min_34c3e57.js"></script><script type="text/javascript" src="/js/lib/jquery.cookie_801d29b.js"></script><script type="text/javascript" src="/js/lib/vue.min_da55047.js"></script><script type="text/javascript" src="/js/lib/vue-i18n.min_26d2756.js"></script><script type="text/javascript" src="/js/lib/tool_f5528ce.js"></script><script>var _hmt;
_hmt = _hmt || [];
(function() {
    var hm = document.createElement('script');
    hm.src = 'https://hm.baidu.com/hm.js?54a6c097c87d817f40d099a1b48226f0';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(hm, s);
}) ();</script><link rel="stylesheet" type="text/css" media="screen and (min-width: 750px)" href="/css/scene/github_37a6c24.css"><link rel="stylesheet" type="text/css" media="screen and (min-width: 750px)" href="/css/scene/scene_b22fa59.css"><style type="text/css">.scene-body .content .github_table{border:unset;height:unset}.markdown-body p,.markdown-body blockquote,.markdown-body ul,.markdown-body ol,.markdown-body dl,.markdown-body table,.markdown-body pre{font-size:14px;color:#666}.markdown-body{font-family:PingFangSC-Regular}.eccv a.submit_achievement{border:#006aff 1px solid;color:#006aff;cursor:pointer}.markdown-body .title-1{font-size:20px;color:#333}.markdown-body .mt60{margin-top:60px!important}.scene-body .content{padding-left:25px}.tip-top{word-wrap:normal}.markdown-body .publication-table{overflow:visible;display:table}.word-1.indent{padding-left:1.2em}.ml40{margin-left:40px}</style></head><body><header class="header main-wrapper"><div class="main clearfix"><a href="/index.html" class="logo fl sub-nav-flag"><img src="/public/img/common/logo_a7cf1b2.png"></a><div class="nav-list-mask"></div><ul class="nav-list fl"></ul><div class="language fr sub-nav-flag"><div class="fl" id="lang-login-container"></div></div><div class="cb sub-nav-flag"></div><div class="sub-nav"><div class="sub-nav-content"><ul class="fr" id="sub-nav-ul"></ul></div></div><div class="nav-prompt fr"><span class="texts fl" id="use_pc_text"></span><span class="mobile-banner-close fr"></span></div><script type="text/javascript" src="/js/nav_e779d94.js"></script></div></header><section class="banner main-wrapper scene-banner" id="banner-container"></section><section class="main-wrapper"><div class="main scene-body" id="scene-container"><div class="menu fl"></div><div class="content fl"><p class="title-1 mt60" id="to_introduction_href">1 · Introduction</p><p class="word-1 mt40">The dataset consists 5165 image pairs and corresponding disparity maps, where 4156 image pairs are used for training, and 1009 image pairs are used for testing. The images are extracted from Apollo dataset. Ground truth has been acquired by accumulating 3D point clouds from Lidar and fitting 3D CAD models to individually moving cars (obtained from 3d car instance understanding dataset). The dataset contains varying traffic conditions with heavy occlusion, which are very challenging.</p><div class="fl mt20 demo"><p><img src="/public/img/stereo/example_003/dis_894533e.png" width="260px"> <img src="/public/img/stereo/example_003/left_233a642.png" width="260px"> <img src="/public/img/stereo/example_003/right_a7ae203.png" width="260px"></p><p><img src="/public/img/stereo/example_004/dis_5b9ac32.png" width="260px"> <img src="/public/img/stereo/example_004/left_73bfec8.png" width="260px"> <img src="/public/img/stereo/example_004/right_08788d2.png" width="260px"></p><p><img src="/public/img/stereo/example_006/dis_07554ac.png" width="260px"> <img src="/public/img/stereo/example_006/left_d7389a6.png" width="260px"> <img src="/public/img/stereo/example_006/right_810fdc0.png" width="260px"></p><p><img src="/public/img/stereo/example_008/dis_f673bb0.png" width="260px"> <img src="/public/img/stereo/example_008/left_ca3cfa9.png" width="260px"> <img src="/public/img/stereo/example_008/right_9ffa0de.png" width="260px"></p></div><div class="cb"></div><p class="title-1 mt60" id="to_data_href">2 · Data Download</p><p class="title-2 mt20">Training data</p><div class="down_list mt20 clearfix"><a class="down_btn fl mr10" value="stereo_train_1.zip">stereo_train_1.zip</a> <a class="down_btn fl mr10" value="stereo_train_2.zip">stereo_train_2.zip</a> <a class="down_btn fl mr10" value="stereo_train_3.zip">stereo_train_3.zip</a></div><p class="title-2 mt20">Testing data</p><div class="down_list mt20 clearfix"><a class="down_btn fl mr10" value="stereo_test.zip">stereo_test.zip</a> </div><div class="cb"></div><p class="title-1 mt60" id="to_dataset_href">3 · Data Structure</p><p class="word-1 mt10">The structure of the dataset is following:</p><p class="word-1 mt10">• intrinsic.txt: intrinsic parameters</p><p class="word-1 mt10">• fg_mask: foreground mask</p><p class="word-1 mt10">• bg_mask: background mask</p><p class="word-1 mt10">• Camera5: images captured by camera 5</p><p class="word-1 mt10">• Camera6: images captured by camera 6</p><p class="word-1 mt10">• disparity: the ground truth disparity</p><p class="word-1 mt10">Note that to show the disparity better, the disparity value is 200 times larger than groundtruth. If you upload results, the results should also be increased 200 times.</p><div class="cb"></div><article class="markdown-body entry-content" itemprop="text"><p class="title-1 mt60" id="to_evaluation_href">4 · Evaluation</p><p class="word-1 mt20">The evaluation code are released on github <a href="https://github.com/ApolloScapeAuto/dataset-api/tree/master/stereo">here</a>.</p><p class="title-1 mt60" id="to_metric_href">5 · Metric formula</p><p class="word-1 mt20">For each image, given the predicted disparity di and the ground truth di*, the metric for evaluation is defined as:</p><img src="/public/img/scene/stereo_de1f7aa.jpg" align="middle" width="400px" style="max-width:100%"><p class="word-1 mt20">Here the mask can be either foreground (fg), background (bg) or the whole region (merge of fg and bg). N is the number of image</p><p class="title-1 mt60" id="to_rules_href">6 · Rules of ranking</p><p class="word-1 mt10">Result benchmark will be:</p><table class="github_table"><thead><tr><th>Rank</th><th>Method</th><th align="center">D1_all</th><th align="center">D1_fg</th><th align="center">D1_bg</th></tr></thead><tbody><tr><td>xxx</td><td align="center">xx</td><td align="center">xx</td><td align="center">xx</td><td align="center">xx</td></tr></tbody></table><p class="title-1 mt60" id="to_submission_href">7 · Format of submission file</p><p class="word-1">{split}/{data_type}/{image_name}</p>data_type: disparity: the estimated disparity</article><div class="mt60" style="font-size:18px;text-align:center">The dataset we released is &nbsp;desensitized street view &nbsp;for academic use only.</div></div><div class="cb"></div></div></section><div class="protocol-bg" id="protocol"></div><div class="protocol_container" id="protocol_container"></div><div class="done_load"></div><script type="text/javascript" src="/js/stereo_636c4b1.js"></script><footer class="footer main-wrapper"><div class="footer-link tc fl"></div><p class="copyright fl" id="copyright"></p><ul class="tooltip"><li id="tip-top" class="tip-item tip-top" style="display:list-item">·µ»Ø¶¥²¿</li><li class="tip-item" style="display:list-item">联系我们</li></ul></footer><script type="text/javascript" src="/js/footer_da9d14a.js"></script></body></html><!--12901982150975723530022210-->
<script> var _trace_page_logid = 1290198215; </script>